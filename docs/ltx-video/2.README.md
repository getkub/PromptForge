# LTX-Video Integration

This guide explains how to use LTX-Video for video generation within the Local LLM Interface.

## Prerequisites

1. Clone the LTX-Video repository:
   ```bash
   git clone https://github.com/Lightricks/LTX-Video ../Lightricks/LTX-Video
   ```

2. Ensure you have the required dependencies:
   - Python 3.8 or higher
   - CUDA-compatible GPU (recommended)
   - FFmpeg installed on your system

## Setup

1. Install LTX-Video dependencies:
   ```bash
   cd ../Lightricks/LTX-Video
   pip install -r requirements.txt
   ```

2. Download the pre-trained models:
   ```bash
   # Follow the model download instructions in the LTX-Video repository
   ```

## Usage

### Basic Video Generation

```python
from llm_interface.video_generator import LTXVideoGenerator

# Initialize the video generator
generator = LTXVideoGenerator(
    model_path="../Lightricks/LTX-Video/models/your_model.pth"
)

# Generate a video
video_path = generator.generate(
    prompt="A beautiful sunset over mountains",
    duration=5,  # seconds
    resolution=(512, 512)
)
```

### Integration with LLM

You can combine LTX-Video with the LLM interface to generate videos based on LLM responses:

```python
from llm_interface.model_client import ModelClient
from llm_interface.prompt_manager import PromptManager
from llm_interface.video_generator import LTXVideoGenerator

# Initialize components
client = ModelClient()
prompt_manager = PromptManager()
video_generator = LTXVideoGenerator()

# Get scene description from LLM
prompt = prompt_manager.format_prompt(
    "creative.templates.scene.description",
    setting="futuristic city",
    mood="mysterious"
)

response = client.chat([{"role": "user", "content": prompt}])

# Generate video based on LLM response
video_path = video_generator.generate(
    prompt=response,
    duration=10,
    resolution=(512, 512)
)
```

## Configuration

Create a configuration file at `config/ltx-video/config.yaml`:

```yaml
model:
  path: "../Lightricks/LTX-Video/models/your_model.pth"
  device: "cuda"  # or "cpu"

generation:
  default_duration: 5
  default_resolution: [512, 512]
  fps: 30
  batch_size: 1

output:
  directory: "output/videos"
  format: "mp4"
```

## Examples

Check the `examples/ltx-video/` directory for sample scripts and use cases:

- Basic video generation
- Text-to-video with LLM integration
- Batch processing
- Custom model fine-tuning

## Troubleshooting

Common issues and solutions:

1. **CUDA Out of Memory**
   - Reduce batch size
   - Lower resolution
   - Use CPU if GPU memory is insufficient

2. **Model Loading Errors**
   - Verify model path
   - Check model compatibility
   - Ensure all dependencies are installed

3. **Video Generation Quality**
   - Adjust prompt specificity
   - Try different model checkpoints
   - Experiment with generation parameters

For more detailed troubleshooting, refer to the [LTX-Video repository](https://github.com/Lightricks/LTX-Video) and the [main troubleshooting guide](../user-guide/troubleshooting.md).

## Advanced Usage

### Custom Model Training

1. Prepare your dataset:
   ```bash
   python scripts/prepare_dataset.py --input_dir your_data --output_dir prepared_data
   ```

2. Train the model:
   ```bash
   python scripts/train.py --config configs/training.yaml
   ```

### Batch Processing

```python
from llm_interface.video_generator import LTXVideoGenerator

generator = LTXVideoGenerator()

# Generate multiple videos
prompts = [
    "A serene forest scene",
    "An urban cityscape at night",
    "Ocean waves crashing on rocks"
]

video_paths = generator.generate_batch(
    prompts=prompts,
    duration=5,
    resolution=(512, 512)
)
```

## Contributing

To contribute to the LTX-Video integration:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

This integration is subject to both the Local LLM Interface license and the LTX-Video license. Please review both licenses before use. 